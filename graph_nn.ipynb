{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "\n",
    "import os\n",
    "import cv2\n",
    "import json\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Data_Loader():\n",
    "    def __init__(self, data_file_path, label_file_path, n_images):\n",
    "        \n",
    "        self.data_file_path = data_file_path\n",
    "        self.label_file_path = label_file_path\n",
    "        self.n_images = n_images\n",
    "    \n",
    "    \n",
    "    def load_image_data(self): \n",
    "        X = []\n",
    "        Y = [] \n",
    "        for file in os.listdir(self.data_file_path):\n",
    "            file_path = os.path.join(self.data_file_path, file)\n",
    "            if file.endswith('.jpg'):\n",
    "                img_annotations = self.__load_annotations(file)\n",
    "                if img_annotations is not None:\n",
    "                    Y.append(img_annotations)\n",
    "                    img = cv2.imread(file_path)\n",
    "                    X.append(img)\n",
    "                if len(X) >= self.n_images :\n",
    "                    return X, Y\n",
    "        return X, Y\n",
    "    \n",
    "    \n",
    "    def __load_annotations(self, image_file_name):\n",
    "        file_name = image_file_name.split('.jpg')[0]\n",
    "        json_file_name = file_name + '.json'\n",
    "        json_file_path = os.path.join(self.label_file_path, json_file_name)\n",
    "        if os.path.isfile(json_file_path):\n",
    "            f = open(json_file_path)\n",
    "            return json.load(f)\n",
    "        else:\n",
    "            return None\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Image_Processor():\n",
    "    \n",
    "    def __init__(self, images):\n",
    "        self.images = images\n",
    "        self.min_width, self.min_height = self.__find_smallest_image_width_and_height()\n",
    "        self.resized_images = self.__resize_images()\n",
    "    \n",
    "    \n",
    "    def __resize_images(self):\n",
    "        \n",
    "        X_resized = []\n",
    "        \n",
    "        for img in self.images:\n",
    "            X_resized.append(tf.image.resize(img, \n",
    "                                             size=(self.min_width, self.min_height)))\n",
    "            \n",
    "        return np.array(X_resized)\n",
    "    \n",
    "    \n",
    "    def __find_smallest_image_width_and_height(self):\n",
    "        \n",
    "        min_width = np.size(self.images[0], 0)\n",
    "        min_height = np.size(self.images[0], 1)\n",
    "        \n",
    "        for img in self.images[1:]:\n",
    "            \n",
    "            if np.size(img, 0) < min_width:\n",
    "                min_width = np.size(img, 0)\n",
    "                \n",
    "            if np.size(img, 1) < min_height:\n",
    "                min_height = np.size(img, 1)\n",
    "                \n",
    "        return min_width, min_height"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model(input_shape):\n",
    "    \n",
    "    model = tf.keras.Sequential()\n",
    "\n",
    "    # add first convolution layer to the model\n",
    "    model.add(tf.keras.layers.Conv2D(\n",
    "        filters=32,\n",
    "        kernel_size=(5, 5),\n",
    "        strides=(1, 1),\n",
    "        padding='same',\n",
    "        data_format='channels_last',\n",
    "        name='conv_1',\n",
    "        activation='relu'))\n",
    "    \n",
    "    \n",
    "    # add a max pooling layer with pool size (2,2) and strides of 2\n",
    "    # (this will reduce the spatial dimensions by half)\n",
    "    model.add(tf.keras.layers.MaxPool2D(\n",
    "        pool_size=(2, 2),\n",
    "        name='pool_1'))\n",
    "    \n",
    "    \n",
    "    # add second convolutional layer\n",
    "    # model.add(tf.keras.layers.Conv2D(\n",
    "    #     filters=64,\n",
    "    #     kernel_size=(5, 5),\n",
    "    #     strides=(1, 1),\n",
    "    #     padding='same',\n",
    "    #     name='conv_2',\n",
    "    #     activation='relu'))\n",
    "    \n",
    "    # # add second max pooling layer with pool size (2,2) and strides of 2\n",
    "    # # (this will further reduce the spatial dimensions by half)\n",
    "    # model.add(tf.keras.layers.MaxPool2D(\n",
    "    #     pool_size=(2, 2), name='pool_2')\n",
    "    # )\n",
    "    \n",
    "    \n",
    "    # add a fully connected layer (need to flatten the output of the previous layers first)\n",
    "    model.add(tf.keras.layers.Flatten())\n",
    "    model.add(tf.keras.layers.Dense(\n",
    "        units=16,\n",
    "        name='fc_1',\n",
    "        activation='relu'))\n",
    "    \n",
    "    # add dropout layer\n",
    "    # model.add(tf.keras.layers.Dropout(\n",
    "    #     rate=0.5))\n",
    "    \n",
    "    # add the last fully connected layer\n",
    "    # this last layer sets the activation function to \"None\" in order to output the logits\n",
    "    # note that passing activation = \"sigmoid\" will return class memembership probabilities but\n",
    "    # in TensorFlow logits are prefered for numerical stability\n",
    "    # set units=1 to get a single output unit (remember it's a binary classification problem)\n",
    "    model.add(tf.keras.layers.Dense(\n",
    "        units=5,\n",
    "        name='fc_2',\n",
    "        activation=None))\n",
    "    \n",
    "    model.build(input_shape=input_shape)\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_file_path = './benetech-making-graphs-accessible/train/images'\n",
    "label_file_path = './benetech-making-graphs-accessible/train/annotations'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_images = 700\n",
    "\n",
    "# Load in raw data\n",
    "X_raw, Y_raw = Data_Loader(data_file_path, \n",
    "                           label_file_path, n_images).load_image_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_processed = Image_Processor(X_raw)\n",
    "X_resized = X_processed.resized_images\n",
    "X_gray = X_resized / 255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_plot_type = [y['chart-type'] for y in Y_raw]\n",
    "\n",
    "plot_type_mapping = {'scatter':0, 'line':1, 'dot':2, 'vertical_bar':3, \n",
    "                       'horizontal_bar':4}\n",
    "Y_plot_type = [plot_type_mapping[plot_type] for plot_type in Y_plot_type]\n",
    "Y_plot_type = np.array(Y_plot_type)\n",
    "shuffle = tf.random.shuffle(tf.range(tf.shape(X_gray)[0], dtype=tf.int32))\n",
    "X_all = tf.gather(X_gray, shuffle)\n",
    "y_all = tf.gather(Y_plot_type, shuffle)\n",
    "\n",
    "split = int(len(X_raw) * 0.8)\n",
    "\n",
    "X_train, Y_train = X_all[:split], y_all[:split]\n",
    "X_val, Y_val = X_all[split:], y_all[split:]\n",
    "\n",
    "model = build_model(\n",
    "     input_shape=(None, X_processed.min_width, X_processed.min_height, 3))\n",
    "\n",
    "model.compile(optimizer=tf.keras.optimizers.Adam(),\n",
    "               loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "               metrics=['accuracy'])\n",
    "\n",
    "history = model.fit(X_train, Y_train,\n",
    "                     epochs=25,\n",
    "                     validation_data=(X_val, Y_val) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Num GPUs Available: \", len(tf.config.list_physical_devices('GPU')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf",
   "language": "python",
   "name": "tf"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
